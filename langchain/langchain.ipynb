{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mi dispiace, non posso fornire informazioni sulla distanza tra due paesi in questa lingua. Il mio nome è Ant. Come posso aiutarti con la geografia?')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Your are a geography expert, Ant you only reply in {language}\"),\n",
    "    AIMessage(content=\"Ciao, mi chiamo {name}\"),\n",
    "    HumanMessage(content=\"What is the distance between {country_a} and {country_b}. Also, what is your name?\")\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Γεια σας! Το όνομά μου είναι Σωκράτης. Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 16.000 χιλιόμετρα.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prompt Templates\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "# template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}\")\n",
    "\n",
    "# prompt = template.format(country_a = \"Mexico\", country_b = \"Thailand\")\n",
    "# chat.predict(prompt)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Your are a geography expert, Ant you only reply in {language}\"),\n",
    "    (\"ai\", \"Ciao, mi chiamo {name}\"),\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}. Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"Greek\",\n",
    "    name=\"Socrates\",\n",
    "    country_a =\"Mexico\",\n",
    "    country_b=\"Thailand\",\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mercury',\n",
       " 'Venus',\n",
       " 'Earth',\n",
       " 'Mars',\n",
       " 'Jupiter',\n",
       " 'Saturn',\n",
       " 'Uranus',\n",
       " 'Neptune',\n",
       " 'Pluto']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OutputParser and LCEL\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items= text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Your are a list generathing machine. Everything you are asked will be answered with a comma seperated list of max {max_items}. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\": 10,\n",
    "    \"question\":\"What are the planets\",\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To make a vegetarian version of Chicken Tikka Masala, we can substitute the chicken with a plant-based alternative such as tofu or paneer. Here's how you can adapt the recipe:\\n\\nIngredients:\\n- 1 lb firm tofu or paneer, cut into bite-sized pieces\\n- 1 cup plain yogurt (you can use dairy-free yogurt for a vegan version)\\n- 2 tablespoons lemon juice\\n- 2 teaspoons ground cumin\\n- 2 teaspoons paprika\\n- 1 teaspoon ground turmeric\\n- 1 teaspoon garam masala\\n- 1 teaspoon ground coriander\\n- 1 teaspoon chili powder (adjust to taste)\\n- Salt and pepper to taste\\n- 2 tablespoons vegetable oil\\n- 1 onion, finely chopped\\n- 3 cloves garlic, minced\\n- 1-inch piece of ginger, grated\\n- 1 can (14 oz) crushed tomatoes\\n- 1 cup coconut cream (or dairy-free heavy cream alternative)\\n- Fresh cilantro, chopped (for garnish)\\n\\nInstructions:\\n1. Follow the same marinating process as the original recipe, but use tofu or paneer instead of chicken. Marinate for at least 1 hour, or overnight for best results.\\n\\n2. Instead of baking the chicken, you can pan-fry the marinated tofu or paneer until golden brown on all sides.\\n\\n3. Proceed with the recipe as instructed, starting with sautéing the onion, garlic, and ginger in vegetable oil.\\n\\n4. Add the crushed tomatoes and simmer for 10 minutes. Then, add the pan-fried tofu or paneer to the sauce and simmer for an additional 5 minutes.\\n\\n5. Stir in the coconut cream (or dairy-free heavy cream alternative) and simmer for another 5 minutes, adjusting the seasoning with salt and pepper if needed.\\n\\n6. Serve the Vegetarian Tikka Masala over steamed rice or with naan bread. Garnish with chopped cilantro before serving.\\n\\nEnjoy your flavorful Vegetarian Tikka Masala with all the richness and aroma of the traditional dish, but with a plant-based twist!\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chaining Chains\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\")\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\"), \n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chef_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\" : chef_chain} | veg_chef_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    'cuisine' : 'indian'\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
